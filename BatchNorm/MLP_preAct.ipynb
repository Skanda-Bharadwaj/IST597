{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_iYcla4kCX67"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import time\n",
    "import random\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "np.random.seed(1234)\n",
    "tf.random.set_seed(1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Kgna3kY6CX67",
    "outputId": "db4d9f30-024f-4fcc-c284-a06acb6ad281"
   },
   "outputs": [],
   "source": [
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 383
    },
    "id": "JodgHy9nCX68",
    "outputId": "3d423aa6-4349-46d8-d995-7013c9e84450"
   },
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = keras.datasets.fashion_mnist.load_data() # Load MNIST or FMNIST\n",
    "assert X_train.shape == (60000, 28, 28)\n",
    "assert X_test.shape  == (10000, 28, 28)\n",
    "assert y_train.shape == (60000,)\n",
    "assert y_test.shape  == (10000,)\n",
    "\n",
    "\n",
    "# Display randomly selected data\n",
    "indices = list(np.random.randint(X_train.shape[0],size=3))\n",
    "for i in range(3):\n",
    "    plt.subplot(1,3,i+1)\n",
    "    plt.imshow(X_train[indices[i]].reshape(28,28), cmap='gray', interpolation='none')\n",
    "    plt.title(\"Index {} Class {}\".format(indices[i], y_train[indices[i]]))\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oIRI-uLoCX69",
    "outputId": "e664546e-92d4-435a-ae37-7f6836d5e783",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Split train dataset into train and validation\n",
    "X_val   = X_train[50000:60000]\n",
    "X_train = X_train[0:50000]\n",
    "y_val   = y_train[50000:60000]\n",
    "y_train = y_train[0:50000]\n",
    "\n",
    "print(\"size of training set is\", str(X_train.shape[0]), \"samples\")\n",
    "print(\"every train example is\", str(X_train.shape[1]), \"by\", str(X_train.shape[2]))\n",
    "\n",
    "print(\"size of validation set is\", str(X_val.shape[0]), \"samples\")\n",
    "print(\"every validation example is\", str(X_val.shape[1]), \"by\", str(X_val.shape[2]))\n",
    "\n",
    "X_train = X_train.reshape(50000, 28*28)\n",
    "X_val = X_val.reshape(10000, 28*28)\n",
    "X_test = X_test.reshape(10000, 28*28)\n",
    "\n",
    "print(\"size of training set is\", str(X_train.shape[0]), \"samples\")\n",
    "print(\"every train example has\", str(X_train.shape[1]), \"features\")\n",
    "\n",
    "print(\"size of validation set is\", str(X_val.shape[0]), \"samples\")\n",
    "print(\"every validation example has\", str(X_val.shape[1]), \"features\")\n",
    "\n",
    "# Split dataset into batches\n",
    "#train_ds = tf.data.Dataset.from_tensor_slices((X_train, y_train)).batch(16)\n",
    "#test_ds = tf.data.Dataset.from_tensor_slices((X_test, y_test)).batch(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mDyZ8bZjCX69",
    "outputId": "4f18de99-636d-4c05-b085-85e37206b037"
   },
   "outputs": [],
   "source": [
    "#Normalize Data\n",
    "\n",
    "X_train = X_train/255\n",
    "X_val   = X_val/255\n",
    "X_test  = X_test/255\n",
    "\n",
    "print(f'max: ', np.max(X_train))\n",
    "print(f'min: ', np.min(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3lIIy313CX69",
    "outputId": "527be8e1-561e-40c7-86ce-069f1955d162"
   },
   "outputs": [],
   "source": [
    "size_input = X_train.shape[1]\n",
    "\n",
    "size_hidden1 = 128\n",
    "size_hidden2 = 128\n",
    "size_hidden3 = 128\n",
    "\n",
    "size_output = 10\n",
    "\n",
    "number_of_train_examples = X_train.shape[0]\n",
    "number_of_test_examples  = X_test.shape[0]\n",
    "\n",
    "y_train = tf.keras.utils.to_categorical(y_train, num_classes=10) # Other function is tf.one_hot(y_train,depth=10)\n",
    "y_val   = tf.keras.utils.to_categorical(y_val, num_classes=10)\n",
    "y_test  = tf.keras.utils.to_categorical(y_test, num_classes=10)\n",
    "\n",
    "print(tf.shape(y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "obN7WPLpCX69"
   },
   "outputs": [],
   "source": [
    "# Define class to build mlp model\n",
    "class MLP(object):\n",
    "    def __init__(self, size_input, size_hidden1, size_hidden2, size_hidden3, size_output, device=None):\n",
    "        \"\"\"\n",
    "        size_input: int, size of input layer\n",
    "        size_hidden1: int, size of the 1st hidden layer\n",
    "        size_hidden2: int, size of the 2nd hidden layer\n",
    "        size_output: int, size of output layer\n",
    "        device: str or None, either 'cpu' or 'gpu' or None. If None, the device to be used will be decided automatically during Eager Execution\n",
    "        \"\"\"\n",
    "        self.size_input, self.size_hidden1, self.size_hidden2, self.size_hidden3, self.size_output, self.device =\\\n",
    "        size_input, size_hidden1, size_hidden2, size_hidden3, size_output, device\n",
    "\n",
    "        # Initialize weights between input mapping and a layer g(f(x)) = layer\n",
    "        self.W1 = tf.Variable(tf.random.normal([self.size_input, self.size_hidden1],stddev=0.1)) # Xavier(Fan-in fan-out) and Orthogonal\n",
    "        # Initialize biases for hidden layer\n",
    "        self.b1 = tf.Variable(tf.zeros([1, self.size_hidden1])) # 0 or constant(0.01)\n",
    "\n",
    "        # Initialize weights between input layer and 1st hidden layer\n",
    "        self.W2 = tf.Variable(tf.random.normal([self.size_hidden1, self.size_hidden2],stddev=0.1))\n",
    "        # Initialize biases for hidden layer\n",
    "        self.b2 = tf.Variable(tf.zeros([1, self.size_hidden2]))\n",
    "\n",
    "        # Initialize weights between 1st hidden layer and 2nd hidden layer\n",
    "        self.W3 = tf.Variable(tf.random.normal([self.size_hidden2, self.size_hidden3],stddev=0.1))\n",
    "        # Initialize biases for hidden layer\n",
    "        self.b3 = tf.Variable(tf.zeros([1, self.size_hidden3]))\n",
    "\n",
    "         # Initialize weights between 2nd hidden layer and output layer\n",
    "        self.W4 = tf.Variable(tf.random.normal([self.size_hidden3, self.size_output],stddev=0.1))\n",
    "        # Initialize biases for output layer\n",
    "        self.b4 = tf.Variable(tf.zeros([1, self.size_output]))\n",
    "\n",
    "        # Initializing gamma and beta for all the layers for batch norm\n",
    "        self.gamma = {\"1\": tf.Variable(tf.ones(self.W1.shape[-1])),\n",
    "                      \"2\": tf.Variable(tf.ones(self.W2.shape[-1])),\n",
    "                      \"3\": tf.Variable(tf.ones(self.W3.shape[-1]))\n",
    "        }\n",
    "        self.beta  = {\"1\": tf.Variable(tf.zeros(self.W1.shape[-1])),\n",
    "                      \"2\": tf.Variable(tf.zeros(self.W2.shape[-1])),\n",
    "                      \"3\": tf.Variable(tf.zeros(self.W3.shape[-1]))\n",
    "        }\n",
    "        # Define variables to be updated during backpropagation\n",
    "        self.variables = [self.W1, self.W2, self.W3, self.W4, \n",
    "                          self.b1, self.b2, self.b3, self.b4, \n",
    "                          self.gamma[\"1\"], self.beta[\"1\"], \n",
    "                          self.gamma[\"2\"], self.beta[\"2\"], \n",
    "                          self.gamma[\"3\"], self.beta[\"3\"]]\n",
    "\n",
    "        self.mean = {\"1\": tf.Variable(tf.zeros(self.W1.shape[-1])),\n",
    "                     \"2\": tf.Variable(tf.zeros(self.W2.shape[-1])),\n",
    "                     \"3\": tf.Variable(tf.zeros(self.W3.shape[-1]))\n",
    "        }\n",
    "        self.var = {\"1\": tf.Variable(tf.zeros(self.W1.shape[-1])),\n",
    "                    \"2\": tf.Variable(tf.zeros(self.W2.shape[-1])),\n",
    "                    \"3\": tf.Variable(tf.zeros(self.W3.shape[-1]))\n",
    "        }\n",
    "  \n",
    "    def forward(self, X, run):\n",
    "        \"\"\"\n",
    "        forward pass\n",
    "        X: Tensor, inputs\n",
    "        \"\"\"\n",
    "        if self.device is not None:\n",
    "            with tf.device('gpu:0' if self.device=='gpu' else 'cpu'):\n",
    "                if run == \"train\":\n",
    "                    self.y = self.compute_output_train(X)\n",
    "                else:\n",
    "                    self.y = self.compute_output_test(X)\n",
    "        else:\n",
    "            if run == \"train\":\n",
    "                self.y = self.compute_output_train(X)\n",
    "            else:\n",
    "                self.y = self.compute_output_test(X)\n",
    "\n",
    "        return self.y\n",
    "\n",
    "    def loss(self, y_pred, y_true):\n",
    "        '''\n",
    "        y_pred - Tensor of shape (batch_size, size_output)\n",
    "        y_true - Tensor of shape (batch_size, size_output)\n",
    "        '''\n",
    "        #y_true_tf = tf.cast(tf.reshape(y_true, (-1, self.size_output)), dtype=tf.float32)\n",
    "        y_true_tf = tf.cast(y_true, dtype=tf.float32)\n",
    "        y_pred_tf = tf.cast(y_pred, dtype=tf.float32)\n",
    "        cce = tf.keras.losses.CategoricalCrossentropy(from_logits=True)\n",
    "        loss_x = cce(y_true_tf, y_pred_tf)\n",
    "        # Use keras or tf_softmax, both should work for any given model\n",
    "        #loss_x = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=y_pred_tf, labels=y_true_tf))\n",
    "\n",
    "        return loss_x\n",
    "\n",
    "    def backward(self, X_train, y_train, opti):\n",
    "        \"\"\"\n",
    "        backward pass\n",
    "        \"\"\"\n",
    "        optimizer = opti\n",
    "\n",
    "        with tf.GradientTape() as tape:\n",
    "            predicted = self.forward(X_train, \"train\")\n",
    "            current_loss = self.loss(predicted, y_train)\n",
    "\n",
    "        grads = tape.gradient(current_loss, self.variables)\n",
    "        optimizer.apply_gradients(zip(grads, self.variables))\n",
    "        \n",
    "    def batch_norm(self, inputs, layer):\n",
    "        mean, var = tf.nn.moments(inputs, [0])\n",
    "        self.mean[layer] = 0.9*self.mean[layer] + 0.1*mean\n",
    "        self.var[layer]  = 0.9*self.var[layer]  + 0.1*var\n",
    "        \n",
    "        return tf.add(tf.divide(tf.multiply(self.gamma[layer], tf.subtract(inputs, mean)), tf.sqrt(var+1e-8)), self.beta[layer])\n",
    "\n",
    "    def compute_output_train(self, X):\n",
    "        \"\"\"\n",
    "        Custom method to obtain output tensor during forward pass\n",
    "        \"\"\"\n",
    "        # Cast X to float32\n",
    "        X_tf = tf.cast(X, dtype=tf.float32)\n",
    "        #X_tf = X\n",
    "\n",
    "        # Compute values in hidden layers\n",
    "        z1 = tf.matmul(X_tf, self.W1) + self.b1\n",
    "        z1 = self.batch_norm(z1, \"1\")\n",
    "        h1 = tf.nn.relu(z1)\n",
    "\n",
    "        z2 = tf.matmul(h1, self.W2) + self.b2\n",
    "        z2 = self.batch_norm(z2, \"2\")\n",
    "        h2 = tf.nn.relu(z2)\n",
    "\n",
    "        z3 = tf.matmul(h2, self.W3) + self.b3\n",
    "        z3 = self.batch_norm(z3, \"3\")\n",
    "        h3 = tf.nn.relu(z3)\n",
    "\n",
    "        # Compute output\n",
    "        output = tf.matmul(h3, self.W4) + self.b4\n",
    "        #output = self.batch_norm(output, \"4\")\n",
    "        #Now consider two things , First look at inbuild loss functions if they work with softmax or not and then change this \n",
    "        # Second add tf.Softmax(output) and then return this variable\n",
    "        return (output)\n",
    "    \n",
    "    def compute_output_test(self, X):\n",
    "        \"\"\"\n",
    "        Custom method to obtain output tensor during forward pass\n",
    "        \"\"\"\n",
    "        # Cast X to float32\n",
    "        X_tf = tf.cast(X, dtype=tf.float32)\n",
    "        #X_tf = X\n",
    "\n",
    "        # Compute values in hidden layers\n",
    "        z1 = tf.matmul(X_tf, self.W1) + self.b1\n",
    "        z1 = tf.add(tf.divide(tf.multiply(self.gamma[\"1\"], tf.subtract(z1, self.mean[\"1\"])), tf.sqrt(self.var[\"1\"])), self.beta[\"1\"])\n",
    "        h1 = tf.nn.relu(z1)\n",
    "\n",
    "        z2 = tf.matmul(h1, self.W2) + self.b2\n",
    "        z2 = tf.add(tf.divide(tf.multiply(self.gamma[\"2\"], tf.subtract(z2, self.mean[\"2\"])), tf.sqrt(self.var[\"2\"])), self.beta[\"2\"])\n",
    "        h2 = tf.nn.relu(z2)\n",
    "\n",
    "        z3 = tf.matmul(h2, self.W3) + self.b3\n",
    "        z3 = tf.add(tf.divide(tf.multiply(self.gamma[\"3\"], tf.subtract(z3, self.mean[\"3\"])), tf.sqrt(self.var[\"3\"])), self.beta[\"3\"])\n",
    "        h3 = tf.nn.relu(z3)\n",
    "\n",
    "        # Compute output\n",
    "        output = tf.matmul(h3, self.W4) + self.b4\n",
    "\n",
    "        #Now consider two things , First look at inbuild loss functions if they work with softmax or not and then change this \n",
    "        # Second add tf.Softmax(output) and then return this variable\n",
    "        return (output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "pOnhvVlUCX6-",
    "outputId": "dba83f32-51dc-412a-b36a-4e3a1868d639"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "***************** Running MLP with pre-activation Batch Normalization for seed 2977 *****************\n",
      "\n",
      "\n",
      "Train Accuracy: 0.8617\n",
      "Number of Epoch = 1 - Average Cross Entropy:= 0.004356533813476562 \n",
      "\n",
      "Validation Accuracy: 0.8495\n",
      "\n",
      "Train Accuracy: 0.8788\n",
      "Number of Epoch = 2 - Average Cross Entropy:= 0.0029947314453125 \n",
      "\n",
      "Validation Accuracy: 0.8659\n",
      "\n",
      "Train Accuracy: 0.8902\n",
      "Number of Epoch = 3 - Average Cross Entropy:= 0.002642081604003906 \n",
      "\n",
      "Validation Accuracy: 0.8721\n",
      "\n",
      "Train Accuracy: 0.9009\n",
      "Number of Epoch = 4 - Average Cross Entropy:= 0.0024121412658691405 \n",
      "\n",
      "Validation Accuracy: 0.8759\n",
      "\n",
      "Train Accuracy: 0.9096\n",
      "Number of Epoch = 5 - Average Cross Entropy:= 0.002219288635253906 \n",
      "\n",
      "Validation Accuracy: 0.8788\n",
      "\n",
      "Train Accuracy: 0.9147\n",
      "Number of Epoch = 6 - Average Cross Entropy:= 0.002058863525390625 \n",
      "\n",
      "Validation Accuracy: 0.8795\n",
      "\n",
      "Train Accuracy: 0.9211\n",
      "Number of Epoch = 7 - Average Cross Entropy:= 0.001903658447265625 \n",
      "\n",
      "Validation Accuracy: 0.8822\n",
      "\n",
      "Train Accuracy: 0.9256\n",
      "Number of Epoch = 8 - Average Cross Entropy:= 0.0017605203247070312 \n",
      "\n",
      "Validation Accuracy: 0.8800\n",
      "\n",
      "Train Accuracy: 0.9294\n",
      "Number of Epoch = 9 - Average Cross Entropy:= 0.00164457275390625 \n",
      "\n",
      "Validation Accuracy: 0.8785\n",
      "\n",
      "Train Accuracy: 0.9341\n",
      "Number of Epoch = 10 - Average Cross Entropy:= 0.0015227243041992188 \n",
      "\n",
      "Validation Accuracy: 0.8782\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total time taken (in seconds): 107.32\n",
      "Test loss: 0.0958\n",
      "\n",
      "Test Accuracy: 0.87\n",
      "\n",
      "\n",
      "***************** Running MLP with pre-activation Batch Normalization for seed 1427 *****************\n",
      "\n",
      "\n",
      "Train Accuracy: 0.8587\n",
      "Number of Epoch = 1 - Average Cross Entropy:= 0.00438836181640625 \n",
      "\n",
      "Validation Accuracy: 0.8476\n",
      "\n",
      "Train Accuracy: 0.8780\n",
      "Number of Epoch = 2 - Average Cross Entropy:= 0.0030348040771484377 \n",
      "\n",
      "Validation Accuracy: 0.8601\n",
      "\n",
      "Train Accuracy: 0.8888\n",
      "Number of Epoch = 3 - Average Cross Entropy:= 0.0026650567626953126 \n",
      "\n",
      "Validation Accuracy: 0.8650\n",
      "\n",
      "Train Accuracy: 0.9002\n",
      "Number of Epoch = 4 - Average Cross Entropy:= 0.0024279241943359377 \n",
      "\n",
      "Validation Accuracy: 0.8714\n",
      "\n",
      "Train Accuracy: 0.9047\n",
      "Number of Epoch = 5 - Average Cross Entropy:= 0.0022358851623535156 \n",
      "\n",
      "Validation Accuracy: 0.8710\n",
      "\n",
      "Train Accuracy: 0.9112\n",
      "Number of Epoch = 6 - Average Cross Entropy:= 0.002071214599609375 \n",
      "\n",
      "Validation Accuracy: 0.8748\n",
      "\n",
      "Train Accuracy: 0.9190\n",
      "Number of Epoch = 7 - Average Cross Entropy:= 0.0019120587158203124 \n",
      "\n",
      "Validation Accuracy: 0.8759\n",
      "\n",
      "Train Accuracy: 0.9236\n",
      "Number of Epoch = 8 - Average Cross Entropy:= 0.0017844329833984374 \n",
      "\n",
      "Validation Accuracy: 0.8789\n",
      "\n",
      "Train Accuracy: 0.9290\n",
      "Number of Epoch = 9 - Average Cross Entropy:= 0.0016624235534667968 \n",
      "\n",
      "Validation Accuracy: 0.8817\n",
      "\n",
      "Train Accuracy: 0.9308\n",
      "Number of Epoch = 10 - Average Cross Entropy:= 0.0015360650634765624 \n",
      "\n",
      "Validation Accuracy: 0.8767\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total time taken (in seconds): 115.79\n",
      "Test loss: 0.1016\n",
      "\n",
      "Test Accuracy: 0.87\n",
      "\n",
      "\n",
      "***************** Running MLP with pre-activation Batch Normalization for seed 9846 *****************\n",
      "\n",
      "\n",
      "Train Accuracy: 0.8614\n",
      "Number of Epoch = 1 - Average Cross Entropy:= 0.004333209228515625 \n",
      "\n",
      "Validation Accuracy: 0.8449\n",
      "\n",
      "Train Accuracy: 0.8805\n",
      "Number of Epoch = 2 - Average Cross Entropy:= 0.0029972756958007813 \n",
      "\n",
      "Validation Accuracy: 0.8608\n",
      "\n",
      "Train Accuracy: 0.8918\n",
      "Number of Epoch = 3 - Average Cross Entropy:= 0.0026356414794921875 \n",
      "\n",
      "Validation Accuracy: 0.8692\n",
      "\n",
      "Train Accuracy: 0.9004\n",
      "Number of Epoch = 4 - Average Cross Entropy:= 0.0024016685485839843 \n",
      "\n",
      "Validation Accuracy: 0.8744\n",
      "\n",
      "Train Accuracy: 0.9084\n",
      "Number of Epoch = 5 - Average Cross Entropy:= 0.002214339141845703 \n",
      "\n",
      "Validation Accuracy: 0.8771\n",
      "\n",
      "Train Accuracy: 0.9153\n",
      "Number of Epoch = 6 - Average Cross Entropy:= 0.0020412139892578124 \n",
      "\n",
      "Validation Accuracy: 0.8782\n",
      "\n",
      "Train Accuracy: 0.9199\n",
      "Number of Epoch = 7 - Average Cross Entropy:= 0.0019056634521484375 \n",
      "\n",
      "Validation Accuracy: 0.8800\n",
      "\n",
      "Train Accuracy: 0.9246\n",
      "Number of Epoch = 8 - Average Cross Entropy:= 0.0017654421997070312 \n",
      "\n",
      "Validation Accuracy: 0.8798\n",
      "\n",
      "Train Accuracy: 0.9310\n",
      "Number of Epoch = 9 - Average Cross Entropy:= 0.0016393472290039063 \n",
      "\n",
      "Validation Accuracy: 0.8785\n",
      "\n",
      "Train Accuracy: 0.9326\n",
      "Number of Epoch = 10 - Average Cross Entropy:= 0.0015347804260253907 \n",
      "\n",
      "Validation Accuracy: 0.8825\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total time taken (in seconds): 111.65\n",
      "Test loss: 0.0923\n",
      "\n",
      "Test Accuracy: 0.88\n"
     ]
    }
   ],
   "source": [
    "seeds = random.sample(range(1000, 9999), 3)\n",
    "for trail in range(3):\n",
    "    \n",
    "    seed = seeds[trail]\n",
    "    \n",
    "    print(f'\\n\\n***************** Running MLP with pre-activation Batch Normalization for seed {seed} *****************\\n')\n",
    "    # Set number of epochs\n",
    "    NUM_EPOCHS = 10\n",
    "\n",
    "    # Initialize model using CPU\n",
    "    mlp_on_gpu = MLP(size_input, size_hidden1, size_hidden2, size_hidden3, size_output, device='gpu')\n",
    "\n",
    "    time_start = time.time()\n",
    "    opti = tf.keras.optimizers.SGD(learning_rate = 0.1)\n",
    "\n",
    "    for epoch in range(NUM_EPOCHS):\n",
    "        loss_total = tf.zeros([1,1], dtype=tf.float32)\n",
    "        lt = 0\n",
    "\n",
    "        train_ds = tf.data.Dataset.from_tensor_slices((X_train, y_train)).shuffle(25, seed=epoch*(seed)).batch(128)\n",
    "        kz = 0\n",
    "        accuracy_z = 0.0\n",
    "        cur_train_acc = 0.0\n",
    "        for inputs, outputs in train_ds:\n",
    "            qw, tr = tf.shape(inputs)\n",
    "            kz = kz + 1\n",
    "            preds = mlp_on_gpu.forward(inputs, \"train\") \n",
    "            loss_total = loss_total + mlp_on_gpu.loss(preds, outputs)\n",
    "            lt = lt + mlp_on_gpu.loss(preds, outputs)\n",
    "            mlp_on_gpu.backward(inputs, outputs, opti)\n",
    "\n",
    "        preds = mlp_on_gpu.forward(X_train, \"train\")\n",
    "        # Get probs, remember we only have logits from our forward function, we need to apply softmax on top of it to get probs\n",
    "        preds = tf.nn.softmax(preds)\n",
    "        correct_prediction = tf.equal(tf.argmax(preds, 1), tf.argmax(y_train, 1))\n",
    "        accuracy_z = accuracy_z + tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
    "        cur_train_acc += accuracy_z.numpy()\n",
    "        ds = cur_train_acc\n",
    "        print('\\nTrain Accuracy: {:.4f}'.format(ds))\n",
    "        print('Number of Epoch = {} - Average Cross Entropy:= {} '.format(epoch + 1, np.sum(loss_total) / X_train.shape[0]))\n",
    "        preds_val = mlp_on_gpu.forward(X_val, \"train\")\n",
    "        preds_val = tf.nn.softmax(preds_val)\n",
    "        correct_prediction = tf.equal(tf.argmax(preds_val, 1), tf.argmax(y_val, 1))\n",
    "\n",
    "        # Calculate accuracy\n",
    "        accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
    "        cur_val_acc = accuracy.numpy()\n",
    "\n",
    "        print('\\nValidation Accuracy: {:.4f}'.format(cur_val_acc))\n",
    "\n",
    "        plt.plot(epoch + 1, np.sum(loss_total) / X_train.shape[0], 'go')\n",
    "        \n",
    "\n",
    "    time_taken = time.time() - time_start\n",
    "    plt.show()\n",
    "    # Validate model\n",
    "\n",
    "\n",
    "\n",
    "    print('\\nTotal time taken (in seconds): {:.2f}'.format(time_taken))\n",
    "    #For per epoch_time = Total_Time / Number_of_epochs\n",
    "\n",
    "    test_loss_total = tf.Variable(0, dtype=tf.float32)\n",
    "    correct_prediction = tf.Variable(0, dtype=tf.float32)\n",
    "\n",
    "\n",
    "    test_ds = tf.data.Dataset.from_tensor_slices((X_test, y_test)).batch(4)\n",
    "\n",
    "\n",
    "    #test_loss_total = 0.0\n",
    "    for inputs, outputs in test_ds:\n",
    "        preds = mlp_on_gpu.forward(inputs, \"test\")\n",
    "        test_loss_total = test_loss_total + mlp_on_gpu.loss(preds, outputs)\n",
    "    print('Test loss: {:.4f}'.format(np.sum(test_loss_total.numpy()) / X_test.shape[0]))\n",
    "\n",
    "    # Test model\n",
    "    preds_test = mlp_on_gpu.forward(X_test, \"test\")\n",
    "    preds_test = tf.nn.softmax(preds_test)\n",
    "    correct_prediction = tf.equal(tf.argmax(preds_test, 1), tf.argmax(y_test, 1))\n",
    "\n",
    "    # Calculate accuracy\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
    "    cur_test_acc = accuracy.numpy()\n",
    "    print('\\nTest Accuracy: {:.2f}'.format(cur_test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "MLP_Fmnist_Saver_optimizer.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

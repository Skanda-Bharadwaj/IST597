{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/AnkurMali/IST597_Spring_2022/blob/main/IST597_Building_CNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "SK3DMbzThNBc"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "np.random.seed(1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WWo3ho3whTWU",
    "outputId": "33ad9b2a-7170-4271-fbb3-739104e08832"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 28, 28, 1)\n",
      "(10000, 28, 28, 1)\n",
      "(10000, 28, 28, 1)\n",
      "391\n",
      "79\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-22 19:25:28.280478: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-03-22 19:25:28.284151: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-03-22 19:25:28.284602: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-03-22 19:25:28.285879: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-03-22 19:25:28.287402: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-03-22 19:25:28.287995: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-03-22 19:25:28.288385: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-03-22 19:25:28.615910: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-03-22 19:25:28.616223: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-03-22 19:25:28.616700: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-03-22 19:25:28.617055: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 7043 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1070, pci bus id: 0000:01:00.0, compute capability: 6.1\n"
     ]
    }
   ],
   "source": [
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.fashion_mnist.load_data()\n",
    "x_val = x_train[50000:60000]\n",
    "x_train = x_train[0:50000]\n",
    "y_val = y_train[50000:60000]\n",
    "y_train = y_train[0:50000]\n",
    "x_train = x_train.astype(np.float32).reshape(-1,28,28,1) / 255.0\n",
    "x_val = x_val.astype(np.float32).reshape(-1,28,28,1) / 255.0\n",
    "x_test = x_test.astype(np.float32).reshape(-1,28,28,1) / 255.0\n",
    "y_train = tf.one_hot(y_train, depth=10)\n",
    "y_val = tf.one_hot(y_val, depth=10)\n",
    "y_test = tf.one_hot(y_test, depth=10)\n",
    "print(x_train.shape)\n",
    "print(x_test.shape)\n",
    "print(x_val.shape)\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
    "train_dataset = train_dataset.shuffle(buffer_size=1024).batch(128)\n",
    "train_dataset_full = train_dataset.shuffle(buffer_size=1024).batch(len(train_dataset))\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((x_val, y_val))\n",
    "val_dataset = val_dataset.batch(128)\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((x_test, y_test))\n",
    "test_dataset = test_dataset.batch(128)\n",
    "print(len(train_dataset))\n",
    "print(len(test_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BatchNormalization(tf.keras.layers.Layer):\n",
    "    def __init__(self, batch_size, training=False):\n",
    "        super(BatchNormalization, self).__init__()\n",
    "\n",
    "        self.convexCoeff = 0.9 \n",
    "        self.numCalls = 0\n",
    "        self.batch_size = batch_size\n",
    "        self.training = training\n",
    "        \n",
    "        self.gamma = self.add_weight(name='gamma', shape=[self.batch_size,], initializer=tf.initializers.ones,  trainable=True)\n",
    "        self.beta  = self.add_weight(name='beta',  shape=[self.batch_size,], initializer=tf.initializers.zeros, trainable=True)\n",
    "        self.mean  = self.add_weight(name='mean',  shape=[self.batch_size,], initializer=tf.initializers.zeros, trainable=False)\n",
    "        self.var   = self.add_weight(name='var',   shape=[self.batch_size,], initializer=tf.initializers.zeros, trainable=False)\n",
    "\n",
    "    def batch_norm(self, inputs, run):\n",
    "        self.numCalls += 1\n",
    "        \n",
    "        if training:\n",
    "            \n",
    "            mean = tf.reduce_mean(inputs, axis=(0, 1, 2))\n",
    "            var  = tf.reduce_variance(inputs, axis(0, 1, 2))\n",
    "            \n",
    "            norm = tf.add(tf.multiply(self.gamma, tf.divide(tf.subtract(inputs, mean), tf.sqrt(var+1e-7))), self.beta)\n",
    "            \n",
    "            mean = mean*self.batch_size[0]/inputs.shape[0]\n",
    "            var  =  var*self.batch_size[0]/inputs.shape[0]\n",
    "            \n",
    "            moving_avg_mean = ((self.convexCoeff/self.numCalls)*mean) + (1-(self.convexCoeff/self.numCalls)*self.mean)\n",
    "            moving_avg_mean = ((self.convexCoeff/self.numCalls)*var)  + (1-(self.convexCoeff/self.numCalls)*self.var)\n",
    "            \n",
    "            self.mean.assign(moving_avg_mean)\n",
    "            self.var.assign(moving_avg_var)\n",
    "            \n",
    "        else:\n",
    "            norm = tf.add(tf.multiply(self.gamma, tf.divide(tf.subtract(inputs, mean), tf.sqrt(var+1e-7))), self.beta)\n",
    "            \n",
    "        return norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "KGjSk_lMhb7V"
   },
   "outputs": [],
   "source": [
    "class ImageRecognitionCNN(tf.keras.Model):\n",
    "    \n",
    "    def __init__(self, num_classes, device='cpu:0', checkpoint_directory=None):\n",
    "        ''' Define the parameterized layers used during forward-pass, the device\n",
    "            where you would like to run the computation (GPU, TPU, CPU) on and the checkpoint\n",
    "            directory.\n",
    "            \n",
    "            Args:\n",
    "                num_classes: the number of labels in the network.\n",
    "                device: string, 'cpu:n' or 'gpu:n' (n can vary). Default, 'cpu:0'.\n",
    "                checkpoint_directory: the directory where you would like to save or \n",
    "                                      restore a model.\n",
    "        ''' \n",
    "        super(ImageRecognitionCNN, self).__init__()\n",
    "        \n",
    "        # Initialize layers\n",
    "        self.conv1 = tf.keras.layers.Conv2D(64, 3, padding='same', activation=None)\n",
    "        self.conv2 = tf.keras.layers.Conv2D(64, 3,padding='same', activation=None)\n",
    "        self.pool1 = tf.keras.layers.MaxPool2D()\n",
    "        self.conv3 = tf.keras.layers.Conv2D(64, 3, padding='same', activation=None)\n",
    "        self.conv4 = tf.keras.layers.Conv2D(64, 3, padding='same', activation=None)\n",
    "        # self.pool2 = tf.keras.layers.MaxPool2D()\n",
    "        # self.conv5 = tf.keras.layers.Conv2D(64, 3, padding='same', activation=None)\n",
    "        # self.pool2 = tf.keras.layers.MaxPool2D()\n",
    "        # self.conv6 = tf.keras.layers.Conv2D(64, 3, 2, padding='same', activation=None)\n",
    "        # self.conv7 = tf.keras.layers.Conv2D(64, 1, padding='same', activation=None)\n",
    "        self.conv8 = tf.keras.layers.Conv2D(num_classes, 1, padding='same', activation=None)\n",
    "        self.BN = BatchNormalization(64)\n",
    "        \n",
    "        # Define the device \n",
    "        self.device = device\n",
    "        \n",
    "        # Define the checkpoint directory\n",
    "        self.checkpoint_directory = checkpoint_directory\n",
    "        self.acc = tf.keras.metrics.Accuracy()\n",
    "\n",
    "\n",
    "    def predict(self, images, training):\n",
    "        \"\"\" Predicts the probability of each class, based on the input sample.\n",
    "            \n",
    "            Args:\n",
    "                images: 4D tensor. Either an image or a batch of images.\n",
    "                training: Boolean. Either the network is predicting in\n",
    "                          training mode or not.\n",
    "        \"\"\"\n",
    "        x = self.conv1(images)\n",
    "        x = self.BN.batch_norm(x, training)\n",
    "        x = tf.nn.relu(x)\n",
    "        x = self.pool1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.BN.batch_norm(x, training)\n",
    "        x = tf.nn.relu(x)\n",
    "        x = self.pool1(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.BN.batch_norm(x, training)\n",
    "        x = tf.nn.relu(x)\n",
    "        x = self.pool1(x)\n",
    "        x = self.conv4(x)\n",
    "        x = self.BN.batch_norm(x, training)\n",
    "        x = tf.nn.relu(x)\n",
    "        x = self.pool1(x)\n",
    "        x = self.conv8(x)\n",
    "        #x = tf.nn.relu(x)\n",
    "        #print(x.shape)\n",
    "        x = tf.reshape(x, (-1, 1, 10))\n",
    "        #x = tf.keras.layers.Flatten(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "\n",
    "    def loss_fn(self, images, target, training):\n",
    "        \"\"\" Defines the loss function used during \n",
    "            training.         \n",
    "        \"\"\"\n",
    "        preds = self.predict(images, training)\n",
    "        #print(preds.shape)\n",
    "        #print(target.shape)\n",
    "        loss = tf.nn.softmax_cross_entropy_with_logits(labels=target, logits=preds)\n",
    "        return loss\n",
    "\n",
    "\n",
    "    def grads_fn(self, images, target, training):\n",
    "        \"\"\" Dynamically computes the gradients of the loss value\n",
    "            with respect to the parameters of the model, in each\n",
    "            forward pass.\n",
    "        \"\"\"\n",
    "        with tf.GradientTape() as tape:\n",
    "            loss = self.loss_fn(images, target, training)\n",
    "        return tape.gradient(loss, self.variables)\n",
    "    \n",
    "    def restore_model(self):\n",
    "        \"\"\" Function to restore trained model.\n",
    "        \"\"\"\n",
    "        with tf.device(self.device):\n",
    "            # Run the model once to initialize variables\n",
    "            dummy_input = tf.constant(tf.zeros((1,48,48,1)))\n",
    "            dummy_pred = self.predict(dummy_input, training=False)\n",
    "            # Restore the variables of the model\n",
    "            saver = tf.Saver(self.variables)\n",
    "            saver.restore(tf.train.latest_checkpoint\n",
    "                          (self.checkpoint_directory))\n",
    "    \n",
    "    def save_model(self, global_step=0):\n",
    "        \"\"\" Function to save trained model.\n",
    "        \"\"\"\n",
    "        tf.Saver(self.variables).save(self.checkpoint_directory, \n",
    "                                       global_step=global_step)   \n",
    "    \n",
    "    # def compute_accuracy(self, input_data):\n",
    "    #     \"\"\" Compute the accuracy on the input data.\n",
    "    #     \"\"\"\n",
    "    #     with tf.device(self.device):\n",
    "    #         #acc = tf.metrics.Accuracy()\n",
    "    #         for step ,(images, targets) in enumerate(input_data):\n",
    "    #             # Predict the probability of each class\n",
    "    #             #print(targets.shape)\n",
    "    #             logits = self.predict(images, training=False)\n",
    "    #             # Select the class with the highest probability\n",
    "    #             #print(logits.shape)\n",
    "    #             logits = tf.nn.softmax(logits)\n",
    "    #             logits = tf.reshape(logits, [-1, 10])\n",
    "    #             targets = tf.reshape(targets, [-1,10])\n",
    "    #             preds = tf.argmax(logits, axis=1)\n",
    "                \n",
    "    #             #m1.update_state\n",
    "    #             # Compute the accuracy\n",
    "    #             #print(preds.shape)\n",
    "    #             acc(tf.reshape(targets, preds))\n",
    "    #     return acc\n",
    "\n",
    "    def compute_accuracy_2(self, images, targets, training=False):\n",
    "        \"\"\" Compute the accuracy on the input data.\n",
    "        \"\"\"\n",
    "        with tf.device(self.device):\n",
    "            \n",
    "            # Predict the probability of each class\n",
    "            logits = self.predict(images, training)\n",
    "            # Select the class with the highest probability\n",
    "            \n",
    "            logits = tf.nn.softmax(logits)\n",
    "            logits = tf.reshape(logits, [-1, 10])\n",
    "            targets = tf.reshape(targets, [-1,10])\n",
    "            preds = tf.argmax(logits, axis=1)\n",
    "            goal = tf.argmax(targets, axis=1)\n",
    "            self.acc.update_state(goal, preds)\n",
    "            # Compute the accuracy\n",
    "            result = self.acc.result().numpy()\n",
    "        return result\n",
    "\n",
    "  \n",
    "    def fit_fc(self, training_data, eval_data, optimizer, num_epochs=500, \n",
    "            early_stopping_rounds=10, verbose=10, train_from_scratch=False):\n",
    "        \"\"\" Function to train the model, using the selected optimizer and\n",
    "            for the desired number of epochs. You can either train from scratch\n",
    "            or load the latest model trained. Early stopping is used in order to\n",
    "            mitigate the risk of overfitting the network.\n",
    "            \n",
    "            Args:\n",
    "                training_data: the data you would like to train the model on.\n",
    "                                Must be in the tf.data.Dataset format.\n",
    "                eval_data: the data you would like to evaluate the model on.\n",
    "                            Must be in the tf.data.Dataset format.\n",
    "                optimizer: the optimizer used during training.\n",
    "                num_epochs: the maximum number of iterations you would like to \n",
    "                            train the model.\n",
    "                early_stopping_rounds: stop training if the loss on the eval \n",
    "                                       dataset does not decrease after n epochs.\n",
    "                verbose: int. Specify how often to print the loss value of the network.\n",
    "                train_from_scratch: boolean. Whether to initialize variables of the\n",
    "                                    the last trained model or initialize them\n",
    "                                    randomly.\n",
    "        \"\"\" \n",
    "    \n",
    "        if train_from_scratch==False:\n",
    "            self.restore_model()\n",
    "        \n",
    "        # Initialize best loss. This variable will store the lowest loss on the\n",
    "        # eval dataset.\n",
    "        best_loss = 999\n",
    "        \n",
    "        # Initialize classes to update the mean loss of train and eval\n",
    "        train_loss = tf.keras.metrics.Mean('train_loss')\n",
    "        eval_loss = tf.keras.metrics.Mean('eval_loss')\n",
    "        acc_train = tf.keras.metrics.Mean('train_acc')\n",
    "        acc_val = tf.keras.metrics.Mean('val_acc')\n",
    "        \n",
    "        # Initialize dictionary to store the loss history\n",
    "        self.history = {}\n",
    "        self.history['train_loss'] = []\n",
    "        self.history['eval_loss'] = []\n",
    "        self.history['train_acc'] = []\n",
    "        self.history['val_acc'] = []\n",
    "        \n",
    "        # Begin training\n",
    "        with tf.device(self.device):\n",
    "            for i in range(num_epochs):\n",
    "                # Training with gradient descent\n",
    "                #training_data_x = training_data.shuffle(buffer_size=1024).batch(128)\n",
    "                for step, (images, target) in enumerate(training_data):\n",
    "                    grads = self.grads_fn(images, target, True)\n",
    "                    optimizer.apply_gradients(zip(grads, self.variables))\n",
    "                    \n",
    "                # Compute the loss on the training data after one epoch\n",
    "                for step, (images, target) in enumerate(training_data):\n",
    "                    loss = self.loss_fn(images, target, False)\n",
    "                    accuracy = self.compute_accuracy_2(images,target)\n",
    "                    acc_train(accuracy)\n",
    "                    train_loss(loss)\n",
    "                self.history['train_loss'].append(train_loss.result().numpy())\n",
    "                self.history['train_acc'].append(acc_train.result().numpy())\n",
    "                # Reset metrics\n",
    "                train_loss.reset_states()\n",
    "                acc_train.reset_states()\n",
    "                \n",
    "                # Compute the loss on the eval data after one epoch\n",
    "                for step, (images, target) in enumerate(eval_data):\n",
    "                    loss = self.loss_fn(images, target, False)\n",
    "                    accuracy = self.compute_accuracy_2(images,target)\n",
    "                    acc_val(accuracy)\n",
    "                    eval_loss(loss)\n",
    "                self.history['eval_loss'].append(eval_loss.result().numpy())\n",
    "                self.history['val_acc'].append(acc_val.result().numpy())\n",
    "                # Reset metrics\n",
    "                eval_loss.reset_states()\n",
    "                acc_val.reset_states()\n",
    "                \n",
    "                # Print train and eval losses\n",
    "                if (i==0) | ((i+1)%verbose==0):\n",
    "                    print('Train loss at epoch %d: ' %(i+1), self.history['train_loss'][-1])\n",
    "                    print('Train Acc at epoch %d: ' %(i+1), self.history['train_acc'][-1])\n",
    "                    \n",
    "                    print('Eval loss at epoch %d: ' %(i+1), self.history['eval_loss'][-1])\n",
    "                    print('Eval Acc at epoch %d: ' %(i+1), self.history['val_acc'][-1])\n",
    "\n",
    "                # Check for early stopping\n",
    "                if self.history['eval_loss'][-1]<best_loss:\n",
    "                    best_loss = self.history['eval_loss'][-1]\n",
    "                    count = early_stopping_rounds\n",
    "                else:\n",
    "                    count -= 1\n",
    "                if count==0:\n",
    "                    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "4a-iuiHIypry"
   },
   "outputs": [],
   "source": [
    "# Specify the path where you want to save/restore the trained variables.\n",
    "checkpoint_directory = 'models_checkpoints/fmnist/'\n",
    "\n",
    "# Use the GPU if available.\n",
    "device = 'gpu:0'\n",
    "\n",
    "# Define optimizer.\n",
    "optimizer = tf.compat.v1.train.AdamOptimizer(learning_rate=1e-4)\n",
    "\n",
    "# Instantiate model. This doesn't initialize the variables yet.\n",
    "model = ImageRecognitionCNN(num_classes=10, device=device, \n",
    "                              checkpoint_directory=checkpoint_directory)\n",
    "\n",
    "#model = ImageRecognitionCNN(num_classes=7, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "exUkL_OBytBw",
    "outputId": "5e19fea2-3fbb-4d67-af3c-0de2cd00e379"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-22 19:26:11.505128: I tensorflow/stream_executor/cuda/cuda_dnn.cc:368] Loaded cuDNN version 8101\n",
      "2022-03-22 19:26:11.639958: W tensorflow/stream_executor/gpu/asm_compiler.cc:111] *** WARNING *** You are using ptxas 11.0.194, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "You may not need to update to CUDA 11.1; cherry-picking the ptxas binary is often sufficient.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_13794/1561449766.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Train model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m model.fit_fc(train_dataset, val_dataset, optimizer, num_epochs=10, \n\u001b[0m\u001b[1;32m      3\u001b[0m           early_stopping_rounds=2, verbose=2, train_from_scratch=True)\n",
      "\u001b[0;32m/tmp/ipykernel_13794/777473988.py\u001b[0m in \u001b[0;36mfit_fc\u001b[0;34m(self, training_data, eval_data, optimizer, num_epochs, early_stopping_rounds, verbose, train_from_scratch)\u001b[0m\n\u001b[1;32m    198\u001b[0m                 \u001b[0;31m#training_data_x = training_data.shuffle(buffer_size=1024).batch(128)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 200\u001b[0;31m                     \u001b[0mgrads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrads_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    201\u001b[0m                     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvariables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_13794/777473988.py\u001b[0m in \u001b[0;36mgrads_fn\u001b[0;34m(self, images, target, training)\u001b[0m\n\u001b[1;32m     86\u001b[0m         \"\"\"\n\u001b[1;32m     87\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGradientTape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvariables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_13794/777473988.py\u001b[0m in \u001b[0;36mloss_fn\u001b[0;34m(self, images, target, training)\u001b[0m\n\u001b[1;32m     73\u001b[0m             \u001b[0mtraining\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m         \"\"\"\n\u001b[0;32m---> 75\u001b[0;31m         \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m         \u001b[0;31m#print(preds.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m         \u001b[0;31m#print(target.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_13794/777473988.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, images, training)\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpool1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_13794/777473988.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, images, training)\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpool1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m_pydevd_bundle/pydevd_cython.pyx\u001b[0m in \u001b[0;36m_pydevd_bundle.pydevd_cython.SafeCallWrapper.__call__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m_pydevd_bundle/pydevd_cython.pyx\u001b[0m in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.trace_dispatch\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m_pydevd_bundle/pydevd_cython.pyx\u001b[0m in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.trace_dispatch\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m_pydevd_bundle/pydevd_cython.pyx\u001b[0m in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.trace_dispatch\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m_pydevd_bundle/pydevd_cython.pyx\u001b[0m in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.do_wait_suspend\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/Softwares/miniconda3/lib/python3.9/site-packages/debugpy/_vendored/pydevd/pydevd.py\u001b[0m in \u001b[0;36mdo_wait_suspend\u001b[0;34m(self, thread, frame, event, arg, exception_type)\u001b[0m\n\u001b[1;32m   1974\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1975\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_threads_suspended_single_notification\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnotify_thread_suspended\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthread_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop_reason\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1976\u001b[0;31m                 \u001b[0mkeep_suspended\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_wait_suspend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthread\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mframe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msuspend_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfrom_this_thread\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mframes_tracker\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1977\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1978\u001b[0m         \u001b[0mframes_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Softwares/miniconda3/lib/python3.9/site-packages/debugpy/_vendored/pydevd/pydevd.py\u001b[0m in \u001b[0;36m_do_wait_suspend\u001b[0;34m(self, thread, frame, event, arg, suspend_type, from_this_thread, frames_tracker)\u001b[0m\n\u001b[1;32m   2009\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2010\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess_internal_commands\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2011\u001b[0;31m             \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.01\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2012\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2013\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcancel_async_evaluation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_current_thread_id\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthread\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Train model\n",
    "model.fit_fc(train_dataset, val_dataset, optimizer, num_epochs=10, \n",
    "          early_stopping_rounds=2, verbose=2, train_from_scratch=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyN3tnOb1BmikfUdRD9RBXpk",
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "IST597_Building_CNN.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
